---
title: "Data Import"
output: github_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)

library(tidyverse)
```

## Data Import

CSV zip files (corresponding to each month) of Citi Bike data for 2017 was downloaded from [the company's system data website](https://s3.amazonaws.com/tripdata/index.html). Originally, we felt it was better to download directly from the data source for reproducibility purposes. However, when using read_csv with the direct URL to the zip, there were several parsing errors and the import failed. This may be due to the size of the files (zips of 25-70 MB). We decided to download the zips of two months and add them to our project's data folder. The data is provided according to the [NYCBS Data Use Policy](https://www.citibikenyc.com/data-sharing-policy). 

```{r Data Import Function}
# removed col names type for now and went with automatic column parsing which seemed to work  well

citibike_import = function(file) {
  
  df = read_csv(file, col_names = TRUE) %>%
    janitor::clean_names() %>% 
    separate(start_time, into = c("start_date", "start_time"), sep = " ") %>% 
    separate(stop_time, into = c("stop_date", "stop_time"), sep = " ") %>% 
    mutate(user_type = tolower(user_type),
           trip_minutes = (trip_duration / 60),
           rider_age = (2017 - birth_year))
    
  df
  
}

citibike_tidy = 
  bind_rows(citibike_import("./data/201701-citibike-tripdata.csv.zip"),
            citibike_import("./data/201703-citibike-tripdata.csv.zip"))


# Reading the data directly from website doesn't work - thousands of parsing failures, even with auto parsing and when specifing column parsing in function
# citibike_import("https://s3.amazonaws.com/tripdata/201701-citibike-tripdata.csv.zip"),
# citibike_import("https://s3.amazonaws.com/tripdata/201703-citibike-tripdata.csv.zip"))



```

